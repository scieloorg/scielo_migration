import argparse
import csv
import json
import os

BUILDER_CSV_FIELD_NAMES = (
    "record,tag,field_name,single,subfield,subfield_name,description".split(",")
)


class DataDictionaryBuilder:
    def __init__(self, file_path):
        self._file_path = file_path

    def _read(self):
        with open(self._file_path, newline="") as csvfile:
            reader = csv.DictReader(
                csvfile, delimiter=",", fieldnames=BUILDER_CSV_FIELD_NAMES
            )
            for row in reader:
                yield row

    def group_by_rec_and_tag(self):
        recs = {}
        for row in self._read():
            rec_name = row["record"]
            tag_number = row["tag"]
            tag = "v" + tag_number.zfill(3)

            recs[rec_name] = recs.get(rec_name) or {}
            recs[rec_name][tag_number] = recs[rec_name].get(tag_number) or {}
            if not recs[rec_name][tag_number]:
                recs[rec_name][tag_number]["description"] = row["description"]
                recs[rec_name][tag_number]["tag"] = tag
                recs[rec_name][tag_number]["field_name"] = row["field_name"]
                recs[rec_name][tag_number]["subfields"] = {}

                recs[rec_name][tag_number]["single"] = bool(row["single"]) or not row[
                    "field_name"
                ].endswith("s")

            if row["subfield"]:
                recs[rec_name][tag_number]["subfields"].update(
                    {row["subfield"]: row["subfield_name"]}
                )
        return recs

    @property
    def data_dictionary(self):
        if (
            not hasattr(self, "_grouped_by_rec_and_field")
            or not self._grouped_by_rec_and_field
        ):
            self._grouped_by_rec_and_field = self.group_by_rec_and_tag()
        return self._grouped_by_rec_and_field or {}

    def get_record_data_dictionary(self, rec_name):
        if (
            not hasattr(self, "_grouped_by_rec_and_field")
            or not self._grouped_by_rec_and_field
        ):
            self._grouped_by_rec_and_field = self.group_by_rec_and_tag()
        return self._grouped_by_rec_and_field.get(rec_name) or {}

    def save(self, output_json_file_path):
        with open(output_json_file_path, "w") as fp:
            fp.write(json.dumps(self.data_dictionary, indent=2))


class ModelBuilder:
    def __init__(self, class_name, data_dictionary):
        if "record" not in class_name.lower():
            class_name = class_name + "Record"
        self._class_name = class_name
        self._data_dictionary = data_dictionary

    def create_base_module(self, class_file_path):
        with open(class_file_path, "w") as fp:
            fp.write("# generated by build\n")
            fp.write(
                "from scielo_classic_website.isisdb.raw_record import RawRecord\n\n\n"
            )

    def create_main_module(self, class_file_path, base_module_name):
        attributes = []
        base_class_name = f"Base{self._class_name}"
        class_code = _class_init_builder(f"{self._class_name}", f"{base_class_name}")
        content = (
            "# generated by build",
            f"from scielo_classic_website.isisdb.{base_module_name} import {base_class_name}\n",
            "",
            f"{class_code}",
        )
        with open(class_file_path, "w") as fp:
            fp.write("\n".join(content))

    def add_class(self, class_file_path):
        blocks = [
            _class_init_builder(f"Base{self._class_name}", "RawRecord"),
        ]
        for rec_name, tag_info in sorted(
            self._data_dictionary.items(), key=lambda x: x[1]["tag"]
        ):
            tag = tag_info.get("tag")
            field_name = tag_info.get("field_name") or tag
            subfields = tag_info.get("subfields") or {}
            single = tag_info.get("single")
            comment = _get_comment(tag, tag_info)
            blocks.append(
                _attribute_builder(
                    field_name,
                    tag,
                    subfields,
                    single,
                    comment,
                )
            )

        with open(class_file_path, "a") as fp:
            fp.write("\n".join(blocks))
            fp.write("\n" * 2)


def _get_comment(tag, tag_info):
    field_name = tag_info.get("field_name") or tag
    subfields = tag_info.get("subfields") or ""
    description = tag_info.get("description")
    return_type = "dict" if subfields else "str"
    return_subfields = subfields and {v: "" for k, v in subfields.items()}
    if return_subfields:
        return_subfields = f"Returns:\n        {return_subfields}"
    rows = [
        "",
        '"""',
        f"{description}",
        f"{tag} {subfields}",
        f"{return_subfields}",
        '"""',
    ]
    comment_rows = []
    for row in rows[1:]:
        comment_rows.append(" " * 8 + row.rstrip() if row else "")
    return "\n".join([c for c in comment_rows if c.strip()])


def _class_init_builder(class_name, parent_class_name):
    return "\n".join(
        (
            f"""# generated by build""",
            f"""class {class_name}({parent_class_name}):""",
            f"""""",
            f"""    def __init__(self, record):""",
            f"""        super().__init__(record)""",
        )
    )


def _attribute_builder(attribute_name, tag, subfields, single, comment=""):
    indent = "\n" + " " * 12
    return "\n".join(
        (
            "",
            f"""    # generated by build""",
            f"""    @property""",
            f"""    def {attribute_name}(self):""",
            f"""{comment}""",
            f"""        if not hasattr(self, '_{attribute_name}'):""",
            f"""            self._{attribute_name} =  self.get_field_content(""",
            f"""                    '{tag}',""",
            f"""                    {subfields},""",
            f"""                    {single}""",
            f"""                )""",
            f"""        return self._{attribute_name}""",
        )
    )


def main():
    parser = argparse.ArgumentParser(description="Models builder")
    subparsers = parser.add_subparsers(title="Commands", metavar="", dest="command")

    generate_model_parser = subparsers.add_parser(
        "generate_model", help=("Generate model")
    )

    generate_model_parser.add_argument(
        "isis_records_defs_csv_file_path",
        help=("CSV file path which contains ISIS Records definitions"),
    )

    generate_model_parser.add_argument("record_type", help=("record type"))

    generate_model_parser.add_argument("class_name", help=("class name"))

    generate_model_parser.add_argument("class_file_path", help=("module file"))
    generate_json_data_dictionary_parser = subparsers.add_parser(
        "generate_json_data_dictionary", help=("Generate data dicionary json file")
    )
    generate_json_data_dictionary_parser.add_argument(
        "isis_records_defs_csv_file_path",
        help=("CSV file path which contains ISIS Records definitions"),
    )

    generate_json_data_dictionary_parser.add_argument(
        "data_dictionary_json_file_path", help=("data dictionary json file path")
    )

    generate_module_parser = subparsers.add_parser(
        "generate_module_py", help=("Generate python module")
    )

    generate_module_parser.add_argument(
        "data_dictionary_json_file_path", help=("data_dictionary json file path")
    )

    generate_module_parser.add_argument("record_type", help=("record type"))

    generate_module_parser.add_argument("class_name", help=("class name"))

    generate_module_parser.add_argument("class_file_path", help=("module file"))

    args = parser.parse_args()
    if args.command == "generate_json_data_dictionary":
        builder = DataDictionaryBuilder(args.isis_records_defs_csv_file_path)
        builder.save(args.data_dictionary_json_file_path)
    elif args.command == "generate_module_py":
        with open(args.data_dictionary_json_file_path) as fp:
            data_dict = json.loads(fp.read())
        builder = ModelBuilder(args.class_name, data_dict[args.record_type])
        builder.create_base_module(args.class_file_path)
        builder.add_class(args.class_file_path)
    elif args.command == "generate_model":
        builder = DataDictionaryBuilder(args.isis_records_defs_csv_file_path)

        data_dictionary_json_file_path, ext = os.path.splitext(
            args.isis_records_defs_csv_file_path
        )
        data_dictionary_json_file_path += ".json"
        builder.save(data_dictionary_json_file_path)
        with open(data_dictionary_json_file_path) as fp:
            data_dict = json.loads(fp.read())

        builder = ModelBuilder(args.class_name, data_dict[args.record_type])

        class_dirname = os.path.dirname(args.class_file_path)
        class_basename = os.path.basename(args.class_file_path)

        base_class_basename = f"base_{class_basename}"
        base_class_file_path = os.path.join(class_dirname, base_class_basename)
        base_module_name, ext = os.path.splitext(base_class_basename)

        builder.create_base_module(base_class_file_path)
        builder.add_class(base_class_file_path)

        builder.create_main_module(args.class_file_path, base_module_name)
    else:
        parser.print_help()


if __name__ == "__main__":
    main()
